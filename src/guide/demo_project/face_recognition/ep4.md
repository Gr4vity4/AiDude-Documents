# การสอนโมเดล AI ตรวจจับการใส่หน้ากากอนามัย YoLo2 Object Detection ในบอร์ด CorgiDude

สวัสดีครับ
หากหลาย ๆ ท่านได้อ่านบทความในร้านที่ผ่าน ๆ มา จะสังเกตุได้ว่ามีการใช้งานโมเดลในตรวจหาวัตถุ ไม่ว่าจะเป็น สิ่งของ รถ ใบหน้า หรือแม้แต่การใส่หน้ากากอนามัย ซึ่งส่วนใหญ่จะใช้โมเดล AI ที่มีชื่อว่า Yolo ในทุกบทความจะมีการใช้โมเดลสำเร็จรูปพร้อมโค้ดให้รัน แต่ถ้าเกิดว่าเราอยากจะสอนโมเดลเองเพื่อดูความแม่นยำ หรือปรับปรุงคุณภาพการจำแนก หรือแม้แต่ปรับโครงสร้างโมเดลจะทำยังไง เดี๋ยวในบทความนี้เราจะมาลองทำกันดูครับ

ในการสอนโมเดลทางเราจะเลือกใช้ Library มีชื่อว่า aXeleRate เป็นชุดโปรแกรมสำเร็จรูปที่ใช้งานง่าย แต่มีประสิทธิภาพ ทุกคนสามารถทำตามได้ โดย AIWintermuteAI เป็นผู้ทำขึ้นมาและเป็น opensource นั่นหมายความว่าเราสามารถเข้าไปดูวิธีการทำงานภายในโค้ดได้เลยครับ

[https://github.com/AIWintermuteAI/aXeleRate](https://github.com/AIWintermuteAI/aXeleRate)

ในการสอนโมเดลปกติเราจะใช้เครื่องที่มีการ์ดจอในการประมวลผลที่สูง ซึ่งมีราคาแพง บางครั้งในการใช้งานที่ไม่ได้สอนโมเดลหรือรันงานตลอด อาจจะไม่จำเป็นหรือใช้งานได้อย่างไม่คุ้มค่า ดังนั้น Google จึงมีเครื่องมือที่เรียกว่า Colab ในการให้เราเขียนโค้ด python เพื่อใช้งานการ์ดจอที่อยู่บนเซิฟเวอร์ได้แบบฟรี ๆ ถ้ารันคำสั่งทิ้งไว้ไม่เกิน 12 ชั่วโมง (ซึ่งในการทำครั้งนี้ก็ไม่เกินอยู่แล้ว) เราจึงเลือกใช้บริการนี้ครับ โดยโค้ดจะจัดไว้เป็นกลุ่มสามารถกดเพื่อรันคำสั่งได้เลย

รายละเอียดโค้ดในการสอนโมเดล : 

[https://colab.research.google.com/drive/1C32H98-Zpi9aWg2j1w93STjuMjdfsZvg?usp=sharing](https://colab.research.google.com/drive/1C32H98-Zpi9aWg2j1w93STjuMjdfsZvg?usp=sharing)

ใน colab นี้มี 
\- การโหลด Dataset ของใบหน้าที่ใส่ Mask ประมาณ 8000 รูป สามารถโหลดไปใช้ในงานอื่นได้
\- เมื่อรันทุกอย่างถูกต้องโค้ดจะทำการสร้างไฟล์ kmodel เพื่อใช้ในบอร์ด CorgiDude ให้เอง

ต่อไปมาดูการรันแต่ละคำสั่ง ใน colab ครับ หลังจากที่ได้เข้า colab ไปแล้ว

![](https://ff.lnwfile.com/_/ff/_raw/ct/h7/2o.png)

สคริปนี้ เป็นการเรียก ใช้ lib
\- กำหนดให้ใช้ tensorflow v1
\- กำหนดให้ใช้ imgaug v0.4
\- git clone lib ของ aXeleRate
\- ทำการต่อ path library ที่โหลดไปใว้ในไฟล์ระบบ
\- ดึงคำสั่งที่เกี่ยวข้องในการรันเข้ามาใช้งาน

![](https://ff.lnwfile.com/_/ff/_raw/26/ej/im.png)

สคริปนี้ 
\- โหลด detasets 
\- ทดสอบแสดงผล datasets

![](https://ff.lnwfile.com/_/ff/_raw/tn/1j/bi.png)

สคริปนี้ เป็นการย้าย datasets เอาใว้ใช้ valid 20% ของ datasets ทั้งหมด

![](https://ff.lnwfile.com/_/ff/_raw/9c/rp/zg.png)

ส่วนนี้เป็นการกำหนด config ในการเทรนโมเดล ซึ่งมีส่วนที่สำคัญดังนี้
\- type เป็นชนิด จะเปลียนได้ 3 แบบ Classifier Detector SegNet (จำแนกภาพ, ตรวจจับ(แบบสีเหลี่ยม),ตรวจจับแบ่งขอบเขตวัตถุ)
\- architecture เป็นโครงสร้างของโมเดล มีให้เลือกตามนี้ครับ (ถ้าเป็น CorgiDude แนะนำให้ใช้ MobileNet ครับ)

![](https://ff.lnwfile.com/_/ff/_raw/g1/k2/os.png)

\- input_size ก็จะเป็นขนาดของรูปที่เราต้องการนำเข้าไปสอน ถ้าเป็น MobileNet ก็จะมี 224,160,128 ประมาณนี้ครับ
\- anchors คือค่ากรอบสี่เหลี่ยมที่จะเกิดขึ้นตอนตรวจจับได้ ถ้าไม่รู้จะใส่อะไรให้คงค่าเดิมไว้ แต่ถ้าใครอยากเปลียนให้ลองอ่านรายละเอียดเพิ่มเติมที่ link ในโค้ดครับ)
\- labels ปกติข้อมูลที่ออกมาจาก dataset จะเป็นตัวเลข ค่านี้จะเป็นตัวจับคู่ระหว่างตัวเลขและชื่อที่เราสามารถอ่านได้
\- full ค่าตรงนี้เป็นการบอกให้โมเดลไปโหลดข้อมูล weight จากโมเดลอื่น (ที่สอนมาดีแล้ว) มาใส่ (จะทำให้การสอนทำได้ไวขึ้น) ถ้าไม่มีจะสุ่มขึ้นมาใหม่
\- actual_epoch เทรนจำนวนกี่รอบ 
\- train_image_folder ที่อยู่รูปที่เราจะเอาใว้เทรน
\- train_annot_folder ที่อยู่เฉลยที่เราจะเอาใว้เทรน
\- valid_image_folder ที่อยู่รูปที่เราจะเอาใว้ทดสอบ
\- valid_annot_folder ที่อยู่เฉลยที่เราจะเอาใว้ทดสอบ
\- batch_size ในการสอนภาพจะถูกโหลดเข้าไปในการ์ดจอ จำนวนนี้บอกว่าจะเอากี่รูป ถ้าคุณมีแรมเยอะสามารถใส่เยอะและทำให้สอนได้เร็วขึ้น
\- learning_rate คืออัตราการเรียนรู้ ถ้ามีค่ามากโมเดลจะเก่งเร็ว แต่ผลลัพท์จะแกว่งไปมา ถ้าค่าน้อยจะตรงกันข้าม
\- saved_folder คือ ที่อยู่ในการบันทึกไฟล์ h5 และ kmodel
\- first_trainable_layer layer ไหนที่จะเริ่มเทรน ถ้าไม่ใส่คือเทรนหมด
\- type บันทึกไฟล์อะไรบ้าง 

![](https://ff.lnwfile.com/_/ff/_raw/kt/dy/08.png)

โค้ดด้านบนนี้ ทดสอบดูว่าเครื่องที่เรารันโค้ดอยู่มีการ์ดจอเชื่อมต่อหรือไม่

![](https://ff.lnwfile.com/_/ff/_raw/t7/8y/qr.png)

โค้ดส่วนนี้เป็นต้นไปโปรแกรมจะเริ่มสอนโมเดลให้ตรวจจับตามข้อมูลที่เราสอนให้มัน และจะทำการบันทึกรอบที่มันสามารถตรวจจับได้ดีที่สุดลงไปเรื่อยๆ
จนกว่าจะเทรนครบจำนวนที่เราตั้งใว้ พอรันจบ โปรแกรมจะเอาไฟล์ที่ดีที่สุดมาแปลงเป็น kmodel เพื่อให้เราสามารถใช้งานได้ต่อไปครับ

![](https://ff.lnwfile.com/_/ff/_raw/yx/1x/3h.png)

โค้ดส่วนนี้ ใช้สำหรับทดสอบรูปดูว่าได้ผลลัพธ์ตรงหรือไม่ 

โมเดลในบทความสอนเสร็จเรียบร้อยสามารถดาวน์โหลดได้จาก : (เผื่อไม่อยากรันโค้ดเอง)

[https://github.com/AiDude-io/CorgiDude/blob/master/models/f_mask_yolo2/F_mask_yolo2_k210.kmodel](https://github.com/AiDude-io/CorgiDude/blob/master/models/f_mask_yolo2/F_mask_yolo2_k210.kmodel)

สำหรับโค้ดที่ใช้รันใน CorgiDude สามารถดาวน์โหลดได้จาก : 

[https://github.com/AiDude-io/CorgiDude/blob/master/models/f_mask_yolo2/f_mask_yolo2.py](https://github.com/AiDude-io/CorgiDude/blob/master/models/f_mask_yolo2/f_mask_yolo2.py)

สำหรับการ flash kmodel สามารถตามอ่านต่อที่บทความนี้ได้เลยครับ

[https://www.aiiotshop.com/b/5](https://www.aiiotshop.com/b/5)

